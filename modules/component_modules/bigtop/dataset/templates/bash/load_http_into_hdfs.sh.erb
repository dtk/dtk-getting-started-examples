#!/bin/bash
dataset_name=$1
owner=$2
file_directory_url=$3
target_directory=$4
su <%= @hdfs_superuser %> -c "hadoop fs -ls ${target_directory} > /dev/null 2>&1"
if [ $? -eq 0 ];
then
  echo "Clear action needed on dataset '${dataset_name}'"
  exit 1
fi

su <%= @hdfs_superuser %> -c "hadoop fs -mkdir -p  ${target_directory}"
su <%= @hdfs_superuser %> -c "hadoop fs -chown ${owner}  ${target_directory}"

files_to_load_path="<%= @config_state_prefix %>--${dataset_name}"
files_loaded_path="<%= @actual_state_prefix %>--${dataset_name}"

rm -rf $files_loaded_path
touch $files_loaded_path
count=0
while read file_name
do 
  http_file="${file_directory_url}/${file_name}"
  if [[ `wget -S --spider $http_file  2>&1 | grep 'HTTP/1.1 200 OK'` ]]; 
  then 
    su ${owner} -c "wget $http_file -O - 2> /dev/null | hadoop fs -put - ${target_directory}/${file_name}"
     RETVAL=$?
     if [[ $RETVAL == 0 ]]; 
     then 
      (( count++ ))
       echo ${file_name} >> $files_loaded_path
     fi
  fi
done <  $files_to_load_path
echo "Loaded ${count} files"
exit 0
